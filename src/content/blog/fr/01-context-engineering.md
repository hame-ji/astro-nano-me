---
title: "üß© Context-driven engineering - contexte mod√®le et contexte humain"
description: "Une r√©flexion sur ce que pourrait √™tre une organisation millim√©tr√©e et contr√¥lable des contextes fournis aux diff√©rents agents auxquels on assigne des t√¢ches d'√©criture de code."
date: "Feb 20 2026"
---

# Context-driven engineering : Optimiser le contexte pour les LLM

Comme tout le monde, je me suis essay√© au _context-driven_ (ou encore _spec-driven_) _engineering_. Sans pouvoir d√©terminer au pourcent pr√®s √† quel point c'est plus efficace que le _yolo-prompting_, je ressens quand m√™me une r√©duction drastique des boucles d'it√©rations avec les agents et une arriv√©e au r√©sultat d√©sir√© beaucoup plus directe.

√Ä force de naviguer dans les eaux troubles de l'IA-marketing, de parcourir moult Discord et contenus g√©n√©r√©s par des LLM sur ¬´ _comment rendre la r√©cup√©ration et l'utilisation du contexte plus efficace_ ¬ª, j'en suis venu √† me poser la question suivante :

> Compte tenu du mod√®le √©conomique des _providers_ de mod√®les SOTA (State of the Art), comment conjuguer **obtention de r√©sultats quasi-d√©terministes** et **co√ªts ma√Ætris√©s** (autant que faire se peut) ?

## Circonscrire le contexte

On sait tous que _"less is more"_. Les fichiers `AGENTS.md` ou `CLAUDE.md` sont rois dans la fixation d'un contexte projet, surtout quand on les utilise avec des patterns de _doc-retrieval_. On pr√©cise nos r√®gles particuli√®res et on contraint le mod√®le √† rester dans les clous.

Ok. Mais est-ce que l'agent √† qui je fais ex√©cuter une **t√¢che d√©finie et circonscrite** a besoin de _tout_ le contexte √† chaque fois ?

## Context-splitting : √©viter la pollution de contexte

Ma conception de la chose est la suivante : id√©alement, un agent assign√© √† une t√¢che de refacto ne devrait avoir **que** le contexte n√©cessaire √† cette refacto. Il n'a pas besoin de conna√Ætre les r√®gles de mise √† jour de la documentation ou l'architecture de d√©ploiement.

On peut m√™me aller plus loin : ce contexte de refactoring devrait √™tre divis√© en p√©rim√®tres distincts. Refactoriser un test, une vue front-end ou une requ√™te SQL n√©cessite des r√®gles pr√©cises et exclusives.

Autrement dit, **un contexte monolithique charg√© syst√©matiquement √† chaque nouvelle session est contre-productif**, que ce soit en termes de qualit√© d'information (le mod√®le perd le focus) ou d'√©conomie de tokens.

## √âconomiser les tokens : cr√©er un "contexte mod√®le"

Admettons que l'on ait param√©tr√© la r√©cup√©ration des contextes de mani√®re si fine qu'un agent de review ne poss√®de que le contexte rapport√© √† sa t√¢che. Pourquoi le lui fournir sous la forme d'un Markdown a√©r√©, destin√© au confort de lecture d'un humain, alors qu'il est destin√© exclusivement √† la machine ?

Il y a bien s√ªr la question de la maintenance de ces fichiers et de leur versionnement qui reste cruciale.

L'enjeu est de trouver une syntaxe all√©g√©e pour les √©crire. L'objectif : conserver la qualit√© s√©mantique tout en r√©duisant la charge sur la fen√™tre de contexte. On pourrait par exemple imaginer remplacer de longs paragraphes par des structures de donn√©es denses (JSON ou YAML minifi√©), ou encore tirer parti du **Prompt Caching** propos√© par les API modernes, qui permet de pr√©-charger un contexte fig√© √† moindre co√ªt.

Pour bien visualiser la diff√©rence de "poids" et d'intention, prenons l'exemple d'une r√®gle de cr√©ation de composants UI.

**1. Le Markdown pour humain (Verbeux, poli, a√©r√©)**

```markdown
# Guide de cr√©ation des composants React

Bienvenue dans la documentation front-end.
Lors de la cr√©ation ou de la refactorisation d'un composant, il est strictement demand√© d'utiliser Tailwind CSS pour la gestion des styles.
De plus, pour garder des composants lisibles, veuillez extraire la logique m√©tier dans des hooks personnalis√©s (custom hooks) si celle-ci d√©passe 20 lignes.
```

**2. Le Markdown pour LLM (Direct, imp√©ratif, listes √† puces)**

```markdown
# Rules: React UI

- Style: Tailwind CSS ONLY. No inline styles.
- Logic: Extract to custom hooks if > 20 lines.
- Output: Return ONLY code, no explanations.
```

**3. L'alternative YAML**

```yaml
rules:
  react_ui:
    style: "Tailwind CSS strictly"
    logic: "Extract to custom hooks (>20 lines)"
    output: "Code only"
```

## Ignorer le contexte "humain"

De la m√™me mani√®re que mon mod√®le pr√©f√©r√© n'a pas besoin de conna√Ætre les secrets de mon `.env`, ne pourrait-on pas s√©parer strictement la documentation humaine (comme un `README.md` classique) du contexte ing√©r√© par l'agent ?

C'est l√† qu'interviennent les fichiers d'ignorance. Pour ma part, j'utilise Kilo Code comme CLI, qui g√®re les fichiers `.kiloignore`. On peut y placer, en plus des exclusions classiques (`node_modules`, builds...), toutes les documentations purement humaines :

```text
# .kiloignore
node_modules/
dist/
.env

# Ignorer le contexte humain pour pr√©server l'attention du LLM
README.md
CONTRIBUTING.md
docs/user_guide/
```

De cette mani√®re, on ne pollue pas l'espace s√©mantique du mod√®le. Il n'ira chercher ses instructions que parmi les fichiers cr√©√©s **sur-mesure** pour lui.

## Limites et conclusion

√âvidemment, cette approche chirurgicale a un co√ªt cognitif pour le d√©veloppeur. La premi√®re limite est la maintenabilit√© : s√©parer le contexte humain du contexte mod√®le implique de maintenir deux sources de v√©rit√© en parall√®le. Le risque de d√©synchronisation entre la documentation officielle et les directives de l'agent est r√©el. La seconde limite est le bruit organisationnel (ou over-engineering) : √† trop vouloir micro-manager les agents en d√©coupant les contextes √† l'extr√™me, on risque de passer plus de temps √† configurer le framework de l'IA qu'√† coder r√©ellement l'application.

En fin de compte, le context engineering est un exercice d'√©quilibriste. Il s'agit de trouver le curseur optimal entre la r√©duction du bruit s√©mantique pour l'IA et la simplicit√© de gestion pour l'humain. C'est une discipline jeune, et nos outils (comme les √©diteurs de code et les CLI) devront √©voluer pour abstraire cette complexit√© et rendre la gestion de ce double contexte transparente.
